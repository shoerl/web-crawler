#!/usr/bin/env python3

import argparse
import json
import socket, ssl
from html.parser import HTMLParser
from urllib.parse import urlparse

DEFAULT_SERVER = "project5.3700.network"
DEFAULT_PORT = 443

class LoginHTMLParser(HTMLParser):
    def handle_starttag(self, tag, attrs):
        if tag == "input" and ('name', 'csrfmiddlewaretoken') in attrs:
            for attr in attrs:
                if attr[0] == 'value':
                    self.token = attr[1]
    
    def get_token(self):
        return self.token


class Crawler:
    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
        self.socket = self.get_initialized_socket()

    def get_initialized_socket(self):
        mysocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        # Wrap socket in TLS so we can use HTTPS
        context = ssl.SSLContext()
        mysocket = context.wrap_socket(mysocket, server_hostname=self.server)
        mysocket.connect((self.server, self.port))
        return mysocket

    def get_decoded_request_response(self, request):
        print("Request to %s:%d" % (self.server, self.port))
        print(request)

        self.socket.send(request.encode('ascii'))

        data = self.socket.recv(10000)
        print(data)
        decoded_data = data.decode('ascii')
        print("Response:\n%s" % decoded_data)
        return decoded_data



    # returns [header, html], where html is a empty string if there is none present
    def get_split_request_response(self, url):
        split_response = self.get_decoded_request_response(url).split("\r\n\r\n", 1)
        # make sure the array is always of size 2 (to make it easier to work with)
        if len(split_response) == 1:
            split_response.append('')

        return split_response


    def parse_header_into_dict(self, header):
        header = header.splitlines()
        header_d = {}
        header_d['Type'], header_d['Code'] = header[0].split(maxsplit=1)
        for line in header[1:]:
            name, value = line.split(': ')
            if name in header_d and isinstance(header_d[name], list):
                header_d[name].append(value)
            elif name in header_d:
                header_d[name] = [header_d[name], value]
            else:
                header_d[name] = value
        return header_d

    def run(self):
        request = ("GET {} HTTP/1.0\r\n"
                   "Connection: keep-alive\r\n\r\n").format("/accounts/login/")
        header, html = self.get_split_request_response(request)
        header_dict = self.parse_header_into_dict(header)
        cookie = header_dict["Set-Cookie"].split(";")[0]
        login_html_parser = LoginHTMLParser()
        login_html_parser.feed(html)
        request_body = "username={}&password={}&csrfmiddlewaretoken={}".format(self.username, self.password, login_html_parser.token)
        request = ("POST {} HTTP/1.0\r\n"
                   "Connection: keep-alive\r\n"
                   "Content-Type: application/x-www-form-urlencoded\r\n"
                   "Content-Length: {}\r\n"
                   "Cookie: {}\r\n\r\n"
                   "{}\r\n\r\n").format("/accounts/login/", len(request_body), cookie, request_body)
        header, html = self.get_split_request_response(request)
        header_dict = self.parse_header_into_dict(header)
        
        cookie = ""
        for item in header_dict["Set-Cookie"]:
            if len(cookie) == 0:
                cookie += item.split(";")[0]
            else:
                cookie += "; " + item.split(";")[0]

        request = ("GET {} HTTP/1.0\r\n"
                   "Connection: keep-alive\r\n"
                   "Cookie: {}\r\n\r\n").format("/fakebook/", cookie)
        header, html = self.get_split_request_response(request)




        # if header_dict['Connection'] == "close":
        #     self.socket = self.get_initialized_socket()

        # print(header_dict)
        # if header_dict['Code'] == "302 Found":
        #     header, html = self.get_split_request_response(header_dict["Location"])
        #     header_dict = self.parse_header_into_dict(header)
        

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()
